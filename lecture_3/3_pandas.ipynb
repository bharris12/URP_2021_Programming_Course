{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is originally created by Justin Kinney from https://github.com/jbkinney/19_urp and has been modified by Ben Harris for the 2021 version of the course"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IF RUNNING IN GOOGLE COLAB\n",
    "\n",
    "Uncomment the cell below and run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir data\n",
    "!curl -o data/crp_information_logo.png https://github.com/bharris12/URP_2021_Programming_Course/blob/main/lecture_3/data/crp_information_logo.png\n",
    "!ls data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 4: Pandas and TF binding site analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will start using Pandas. Pandas is the standard way of working with columnar data. However, there is a substantial learning curve. If you want to learn more about Pandas, here is a useful site: http://pandas.pydata.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will use Pandas to analyze transcription factor (TF) binding sites from *Escherichia coli*. We will first focus on CRP, a major regulator in *E. coli* with over 350 functional binding sites.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas is a library for working with tabular data. I was orignally based on the R data.frame library, but with a slightly different grammer and some different functionality. \n",
    "\n",
    "It also can feel really similar to working in SQL.\n",
    "\n",
    "There are two main types of objects in Pandas.\n",
    "\n",
    "### Let's orient ourselves with the objects:\n",
    "\n",
    "1) `pd.Series`\n",
    " * A single column of data\n",
    " * Contains rownames but no column name, the rownames are always reffered to as `pd.Series.index`\n",
    " * Can have an attribute `pd.Series.name` that can serve as the column name\n",
    " * Works a lot like a python dictionary\n",
    "\n",
    "<img src='https://pandas.pydata.org/docs/_images/01_table_series.svg'>\n",
    "\n",
    "2) `Dataframe`\n",
    "\n",
    "* A 2-D object\n",
    "* Each individual column is a Series\n",
    "* Now it has row (index) and column names\n",
    "* The orientation of rows vs columns matters a lot\n",
    "* Generally, you want features as columns and observations as rows\n",
    "\n",
    "\n",
    "<img src='https://pandas.pydata.org/docs/_images/01_table_dataframe.svg'>\n",
    "\n",
    "\n",
    "### What are features and Observations?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install palmerpenguins\n",
    "from palmerpenguins import load_penguins\n",
    "load_penguins().sample(frac=.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features are variables, they are the things you measure, whether that be quantitatively or qualitatively\n",
    "\n",
    "While observations are each data point, in this case it is each penguin\n",
    "### Things we need to learn \n",
    "1) How to create a pandas object/ read data in\n",
    "\n",
    "2) How to subset your data\n",
    "\n",
    "3) How to manipulate/mutate your data to create more data\n",
    "\n",
    "4) How to Summarize or aggregate your data\n",
    "\n",
    "\n",
    "\n",
    "## Preparing Code 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This is needed everytime you run this if you run on google colab\n",
    "!pip -q install logomaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put this first\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Import logomaker; we will use this later for visualizing TF motifs.\n",
    "import logomaker "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will be analyzing a standing database of TF binding sites, which is available on RegulonDB. \n",
    "# Here is a command for downloading this file (this didn't work in lecture 1)\n",
    "!wget -O data/binding_site_db.txt http://regulondb.ccg.unam.mx/menu/download/datasets/files/BindingSiteSet.txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see what this database looks like\n",
    "!head -n 50 data/binding_site_db.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading data\n",
    "\n",
    "When you store your data as a file you can use one of the `pd.read_*` functions to read in data from a variety of different file types\n",
    "\n",
    "Then to save your progress you can write using `pd.DataFrame.write_*`\n",
    "\n",
    "<img src='https://pandas.pydata.org/docs/_images/02_io_readwrite.svg'>\n",
    "\n",
    "\n",
    "There are quite a lot of file types, and they all have their pros/cons. The simpliest ones are `.csv` and `.txt` these are known as flat files and are what we are using today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To parse this file, use Pandas's method read_csv. \n",
    "# We pass the name of this file, as well as other keyword arguments:\n",
    "#     sep='\\t': columns are delimited by tabs\n",
    "#     comment='#': ignore rows that begin with this\n",
    "#     header=None: the first row is NOT the name of the columns\n",
    "# The results are stored as an object known as a dataframe\n",
    "df = pd.read_csv(\"data/binding_site_db.txt\", sep='\\t', comment='#', header=None)\n",
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To check that the data has been properly loaded, call the method df.head()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You get the number of rows and columns from the attribute df.shape\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We only want the TF name (column 1) and the TF binding site sequence (column 11)\n",
    "# To keep only these columns, index the df using a list of column names you want (in the order you want)\n",
    "col_names = [1,11]\n",
    "df = df[col_names]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data frames allow users to give columns meaningful names.\n",
    "# To rename the columns, set df.columns to a list of the desired names.\n",
    "df.columns = ['tf','site']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We see that some TF sites are listed as NaN. \n",
    "# Let's use the dropna() method to get rid of these rows.\n",
    "df = df.dropna()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that the last three modifications of df can be accomplished in one line \n",
    "df = pd.read_csv(\"data/binding_site_db.txt\", sep='\\t', comment='#',\n",
    "                 header=None, usecols=[1,11], names=['tf','site']).dropna()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out the pd.read_csv() documentation for a full list\n",
    "pd.read_csv?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe columns are called 'Series' objects. \n",
    "# Essentially, they're numpy arrays with some extra sugar.\n",
    "col = df['tf']\n",
    "col.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can extract an element from a dataframe by using .loc[]\n",
    "df.loc[3,'site']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to generate sequence logos that represents the binding preferences of TFs in this database.  As a concrete example we'll use CRP, which has a well-characterized binding motif shown here:\n",
    "\n",
    "<img src=\"./data/crp_information_logo.png\" alt=\"Drawing\" style=\"width: 700px;\"/>\n",
    "\n",
    "## Subsetting dataframe\n",
    "\n",
    "In the Zen of Python they say **There should be one-- and preferably only one --obvious way to do it.**\n",
    "\n",
    "Unfortunately when it comes to subsetting rows and columns in pandas that is not the case\n",
    "\n",
    "<img src='https://pandas.pydata.org/docs/_images/03_subset_columns.svg' width='700px'>\n",
    "\n",
    "<img src='https://pandas.pydata.org/docs/_images/03_subset_rows.svg' width='700px'>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a TF\n",
    "tf = 'CRP'\n",
    "\n",
    "# Flag which rows in the dataframe have the correct TF name\n",
    "flags = (df['tf']==tf)\n",
    "flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Grab those rows. To be safe use copy() to make sure that, if we\n",
    "# alter tf_df, df itself doesn't change\n",
    "tf_df = df[flags].copy()\n",
    "tf_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting rows by a boolean vector, like `flags` is basically the only way I ever subset my rows. When you store rows as observations this is generally the case because you usually are **filtering** the rows based on a specific feature.\n",
    "\n",
    "### All the ways to subset DataFrames\n",
    "\n",
    "#### Rows\n",
    "By boolean : `df[BOOLEAN_VECTOR]` \n",
    "\n",
    "By name : `df.loc[LIST_OF_ROW_NAMES, :]`\n",
    "\n",
    "By Location : `df.iloc[LIST_OF_INTEGERS, :]`\n",
    "\n",
    "\n",
    "\n",
    "With a function `df.query('COLUMMN==value')` (This one is quite advanced, see [this tutorial for more](https://www.sharpsightlabs.com/blog/pandas-query/))\n",
    "#### Columns\n",
    "By boolean : `df.loc[:,BOOLEAN_VECTOR]`\n",
    "\n",
    "By name** : `df[LIST_OF_COLUMN_NAMES]`\n",
    "\n",
    "By Location : `df.iloc[:,LIST_OF_INTEGERS]`\n",
    "\n",
    "With a function : `df.filter(LOTS_OF_OPTIONS)` (This one is quite advanced, see [this tutorial for more](https://www.sharpsightlabs.com/blog/pandas-filter/))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each DNA binding site should be capitalized.\n",
    "# To do this, we reset 'site' column of tf_df\n",
    "\n",
    "# Get list of capitalized sites and replace the 'site' column with this\n",
    "capitalized_sites = [site.upper() for site in tf_df['site']]\n",
    "tf_df['site'] = capitalized_sites\n",
    "tf_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to derive a motif, all sites we analyze need to be the same length.\n",
    "# It's good to check that this is actually the case.\n",
    "# We therefore add a column to tf_df listing the length of each site\n",
    "\n",
    "# Compute the length of each site and record this in a 'length' column\n",
    "site_lengths = [len(site) for site in tf_df['site']]\n",
    "tf_df['length'] = site_lengths\n",
    "tf_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises, part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**E4.1.** Use the `unique()` method to determine the lengths of the listed TF binding sites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**E4.2.** Apparently these sites have a bunch of different lengths. For a better understanding of this, write a `for` loop to determine how many sites there are of each length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The 'groupby' method provides a much more convenient way to\n",
    "# tally up different binding site lengths -- as well as to do a \n",
    "# whole host of other computations on data frames. \n",
    "tf_df.groupby('length').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the mode() method to compute the most common binding site length\n",
    "# Note that mode() returns a tuple, of which we need to manually extract the first element\n",
    "length_mode = tf_df['length'].mode()[0]\n",
    "length_mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flag rows having sites of the chosen length\n",
    "flags = (tf_df['length']==length_mode)\n",
    "\n",
    "# Only keep these rows\n",
    "tf_df = tf_df[flags]\n",
    "tf_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now extract the 'site' column from tf_df\n",
    "sites = tf_df['site']\n",
    "sites.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using logomaker.alignment_to_matrix function, compute the number of times each base occurs at each position\n",
    "# Note that this returns a dataframe\n",
    "counts_mat = logomaker.alignment_to_matrix(sites)\n",
    "counts_mat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This counts matrix can be visualized as a sequence logo\n",
    "logomaker.Logo(counts_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises, part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**E4.3.** Counts logos shown above aren't what people use in publications. Rather, they typically use \"information\" logos, like the one shown earlier. By making use of the keyword argument  `to_type='information'` in the function `logomaker.alignment_to_matrix()`, create a CRP information logo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**E4.4.** Using the `.groupby()` and `.sort_values()` methods of the dataframe `df`, create a new dataframe that lists the number of binding sites for each TF, sorted from most sites to least sites. You will need to set two keyword arguments in `.sort_values()`: `by='site'` and `ascending=False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**E4.5.** Fill out the function below so that the user can pass the name of any TF and get list of aligned sites back. Test that it works, e.g. on `tf='FNR'`, by getting a list of sites and making an information logo. Also test that it fails when it is supposed to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's turn this into a function \n",
    "def get_tf_sites(tf):\n",
    "   \n",
    "    # Load database\n",
    "    df = pd.read_csv(\"data/binding_site_db.txt\", sep='\\t', comment='#',\n",
    "                 header=None, usecols=[1,11], names=['tf','site']).dropna()\n",
    "    \n",
    "    # \n",
    "    # Fill in stuff here\n",
    "    # \n",
    "    \n",
    "    # Get sequence alignment and return it\n",
    "    return tf_df['site']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
